{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop (params_rn, num_entradas, num_ocultas, num_etiquetas, X, Y, reg ):\n",
    "\n",
    "    #Obtenemos theta1 y theta2\n",
    "    theta1 = np.reshape(params_rn [:num_ocultas * (num_entradas + 1)],\n",
    "    (num_ocultas, (num_entradas + 1) ) )\n",
    "    theta2 = np.reshape(params_rn [num_ocultas * (num_entradas + 1):],\n",
    "    ( num_etiquetas, (num_ocultas + 1) ) )\n",
    "    \n",
    "    #Añadimos una columna de unos a las X\n",
    "    unos = np.ones([X.shape[0],1])\n",
    "    _X = np.concatenate((unos,X),axis=1)    \n",
    "    \n",
    "    #Hallamos la hipótesis para las theta dadas, esto es necesario para el calculo del coste\n",
    "    h = hipotesis(_X,theta1,theta2).T\n",
    "\n",
    "    #Calculamos el coste con regularización\n",
    "    coste = coste_Reg(h, Y, theta1, theta2, num_etiquetas, reg)\n",
    "    grad = retro_propagacion(_X, Y, theta1, theta2, reg, num_etiquetas)\n",
    "\n",
    "    return coste, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coste_NR(h,Y,num_etiquetas):\n",
    "    \n",
    "    coste=0\n",
    "    m = Y.shape[0]\n",
    "    \n",
    "    for i in range(num_etiquetas):\n",
    "       \n",
    "        _Y = (Y==i+1)*1\n",
    "        coste += sum(-_Y*(np.log(h[i])) - (1-_Y)*(np.log(1-h[i])))\n",
    "        \n",
    "    return coste/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coste_Reg(h, Y, theta1, theta2, num_etiquetas, reg):\n",
    "    \n",
    "    m = Y.shape[0]\n",
    "    theta1[0] = 0.0\n",
    "    theta2[0] = 0.0\n",
    "    \n",
    "    coste = coste_NR(h,Y,num_etiquetas)\n",
    "    coste += (sum(sum(theta1**2)) + sum(sum(theta2**2))) * (reg/m*2)\n",
    "    \n",
    "        \n",
    "    return coste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(Z):\n",
    "  \n",
    "    return 1/(1 + (math.e ** -Z))\n",
    "\n",
    " \n",
    "def derivada_sig(Z):\n",
    "    \n",
    "    return sigmoide(Z)*(1-sigmoide(Z))\n",
    "        \n",
    "        \n",
    "def hipotesis(X,theta1,theta2):\n",
    "    \n",
    "    #Capa primera - Capa oculta\n",
    "    a_1 = sigmoide(X.dot(theta1.T))\n",
    "    unos = np.ones([a_1.shape[0],1])\n",
    "    \n",
    "    #Capa oculta - Capa salida\n",
    "    a_1 = np.concatenate((unos,a_1),axis=1)\n",
    "    a_2 = sigmoide(a_1.dot(theta2.T))\n",
    "    \n",
    "    return a_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pesosAleatorios(L_in, L_out):\n",
    "    \n",
    "    e_ini = 0.12\n",
    "    pesos = np.random.uniform(-e_ini,e_ini,size=(L_out, L_in+1))\n",
    "    return pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retro_propagacion(X, Y, theta1, theta2, reg, num_etiquetas):\n",
    "        \n",
    "    y = np.zeros((Y.shape[0],num_etiquetas))\n",
    "    m = Y.shape[0]\n",
    "    \n",
    "    for i in range (num_etiquetas):\n",
    "\n",
    "        y[i, Y[i]-1] = 1 \n",
    "        \n",
    "     #Capa primera - Capa oculta\n",
    "    a_1 = sigmoide(X.dot(theta1.T))\n",
    "    unos = np.ones([a_1.shape[0],1])\n",
    "    \n",
    "    #Capa oculta - Capa salida\n",
    "    a_2 = np.concatenate((unos,a_1),axis=1)\n",
    "    a_3 = sigmoide(a_2.dot(theta2.T))\n",
    "    \n",
    "    \n",
    "    sigma3 = a_3 - y\n",
    "    sigma2 = sigma3.dot(theta2)[:,1:]\n",
    "    sigma2 = sigma2 * derivada_sig(X.dot(theta1.T))\n",
    "    delta1 = sigma2.T.dot(X)\n",
    "    delta2 = sigma3.T.dot(a_2)\n",
    "\n",
    "    grad1 = delta1/m\n",
    "    grad2 = delta2/m\n",
    "    \n",
    "    theta1[:,1]=0\n",
    "    theta2[:,1]=0\n",
    "    grad1 = grad1+(reg/m)*theta1\n",
    "    grad2 = grad2+(reg/m)*theta2\n",
    "    \n",
    "    #Devolvemos el gradiente como una sola linea    \n",
    "    return np.concatenate((np.ravel(grad1),np.ravel(grad2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aprendizajeRN(X, Y, params, num_entradas, num_ocultas, num_etiquetas, lamb):\n",
    "    \n",
    "    \n",
    "    m = Y.shape[0]\n",
    "    \n",
    "    #Función que entrena la red neuronal\n",
    "    fmin = opt.minimize(fun=backprop, x0=params, \n",
    "                        args=(num_entradas, num_ocultas, num_etiquetas, X, Y, lamb),\n",
    "                        method='TNC', jac=True, options={'maxiter':30})\n",
    "    \n",
    "    #Obtenemos las theta del entrenamiento\n",
    "    theta1 = np.reshape(fmin.x [:num_ocultas * (num_entradas + 1)],\n",
    "    (num_ocultas, (num_entradas + 1) ) )\n",
    "    theta2 = np.reshape(fmin.x [num_ocultas * (num_entradas + 1):],\n",
    "    ( num_etiquetas, (num_ocultas + 1) ) )\n",
    "    \n",
    "    unos = np.ones([X.shape[0],1])\n",
    "    _X = np.concatenate((unos,X),axis=1)\n",
    "    \n",
    "    #Comprobamos la fidelidad del entrenamiento con los casos de prueba\n",
    "    res = hipotesis(_X,theta1,theta2)\n",
    "    \n",
    "    result = np.argmax(res,axis=1) \n",
    "    \n",
    "    result = (result+1 == (Y))*1\n",
    "    \n",
    "    porcentaje = (sum(result)*100)/m\n",
    "\n",
    "    print(\"Término de regularización: \", lamb)\n",
    "    print(\"Númeo de iteraciones: \", 30)\n",
    "    print(\"Porcentaje de acierto: \", porcentaje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Término de regularización:  100\n",
      "Númeo de iteraciones:  30\n",
      "Porcentaje de acierto:  94.1\n"
     ]
    }
   ],
   "source": [
    "def main1():\n",
    "    \n",
    "    #Almacenamos los datos leídos en X, Y.\n",
    "    data = loadmat('ex4data1.mat')\n",
    "    Y = data['y']\n",
    "    X = data['X']\n",
    "    Y = np.array(Y.T)[0]\n",
    "    \n",
    "    \n",
    "    weights = loadmat('ex4weights.mat')\n",
    "    theta1, theta2 = weights ['Theta1'] , weights ['Theta2']\n",
    "\n",
    "    # Theta1 e s de dimensión 25 x 401\n",
    "    # Theta2 e s de dimensión 10 x 26\n",
    "    \n",
    "    \n",
    "    theta_vec = np.concatenate((np.ravel(theta1),np.ravel(theta2)))\n",
    "    num_entradas = theta1.shape[1]-1\n",
    "    num_ocultas = theta1.shape[0]\n",
    "    \n",
    "    aprendizajeRN(X,Y,theta_vec,num_entradas, num_ocultas, 10, 100)\n",
    "\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "main1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
